{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class db_class:\n",
    "    def __init__(self, path, support):\n",
    "        self.db = self.read_database(path)\n",
    "        self.support = support\n",
    "        self.prefix = []\n",
    "        self.result = []\n",
    "        self.PrefixSpan(self.db, self.support, self.prefix)\n",
    "    \n",
    "    def find_project_db(self, db):\n",
    "        item_dict = {}\n",
    "        project_db = {}\n",
    "        for row in db:\n",
    "            visited = set()\n",
    "            for i, item in enumerate(row):\n",
    "                if item not in item_dict:\n",
    "                    item_dict[item] = 1\n",
    "                    project_db[item] = []\n",
    "                    _project_item = [s for s in row[i+1:]]\n",
    "                    if len(_project_item) > 0:\n",
    "                        project_db[item].append(_project_item)\n",
    "                    visited.add(item)\n",
    "                elif (item in item_dict) and (item not in visited):\n",
    "                    item_dict[item] += 1\n",
    "                    _project_item = [s for s in row[i+1:]]\n",
    "                    if len(_project_item) > 0:\n",
    "                        project_db[item].append(_project_item)\n",
    "                    visited.add(item)\n",
    "                   \n",
    "        return project_db, item_dict\n",
    "    \n",
    "    def PrefixSpan(self, database, support, prefix):\n",
    "        if len(database) < 1:\n",
    "            return\n",
    "        prefix = prefix\n",
    "        db = database\n",
    "        project, item_dict = self.find_project_db(db)\n",
    "\n",
    "        remove = []\n",
    "        for item, ncount in item_dict.items():\n",
    "            if ncount < support:\n",
    "                remove.append(item)\n",
    "            else:\n",
    "                r = prefix + [item]\n",
    "                self.result.append((r, ncount))\n",
    "        for item in remove:\n",
    "            del item_dict[item]\n",
    "            del project[item]\n",
    "\n",
    "        for item, project_db in project.items():\n",
    "            next_prefix = prefix + [item]\n",
    "            self.PrefixSpan(project_db, support, next_prefix)\n",
    "        return\n",
    "\n",
    "    def read_database(self, input_dir):\n",
    "        db = []\n",
    "        with open(input_dir, newline='') as csvfile:\n",
    "            rows = csv.reader(csvfile)\n",
    "            for row in rows:\n",
    "                clean_row = [int(s) for s in row]\n",
    "                db.append(clean_row)\n",
    "        return db\n",
    "    \n",
    "    def dump_result(self, output_dir):\n",
    "        result_sorted = sorted(self.result)\n",
    "        with open(output_dir, 'w') as f:\n",
    "            for sequence, item_dict in result_sorted:\n",
    "                f.write('[')\n",
    "                for i, word in enumerate(sequence):\n",
    "                    f.write(str(word))\n",
    "                    if i != len(sequence) - 1:\n",
    "                        f.write(',')\n",
    "                f.write('],{}\\n'.format(item_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1\n",
    "# input file: dataset_1.csv\n",
    "# output_file: output_1.txt\n",
    "#support = 2\n",
    "#db_class('.\\\\publicdataset_1.csv',support).dump_result('.\\\\output_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1\n",
    "# input file: dataset_1.csv\n",
    "# output_file: output_1.txt\n",
    "support = 2\n",
    "db_class('.\\\\dataset_1.csv',support).dump_result('.\\\\output_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_2\n",
    "# input file: dataset_2.csv\n",
    "# output_file: output_2.txt\n",
    "support = 2\n",
    "db_class('.\\\\dataset_2.csv',support).dump_result('.\\\\output_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_3\n",
    "# input file: dataset_3.csv\n",
    "# output_file: output_3.txt\n",
    "support = 2\n",
    "db_class('.\\\\dataset_3.csv',support).dump_result('.\\\\output_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_4\n",
    "# input file: dataset_4.csv\n",
    "# output_file: output_4.txt\n",
    "support = 3\n",
    "db_class('.\\\\dataset_4.csv',support).dump_result('.\\\\output_4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_5\n",
    "# input file: dataset_5.csv\n",
    "# output_file: output_5.txt\n",
    "support = 4\n",
    "db_class('.\\\\dataset_5.csv',support).dump_result('.\\\\output_5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_6\n",
    "# input file: dataset_6.csv\n",
    "# output_file: output_6.txt\n",
    "support = 4\n",
    "db_class('.\\\\dataset_6.csv',support).dump_result('.\\\\output_6.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
